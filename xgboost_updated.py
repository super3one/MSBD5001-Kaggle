# -*- coding: utf-8 -*-
"""xgboost_updated.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cSH75EAdQ4H19pnWRmtXpqdBzYPGtc9k

## Fill-in value
"""

# packages needed upload
import pandas as pd
import matplotlib.pyplot as plt

# train data file
df = pd.read_csv('/content/train.csv')
df.iloc[:5]

# maps the time columns to datetime dtype
df['date'] = pd.to_datetime(df['date'], format='%d/%m/%Y %H:%M')
df.iloc[:5]

# generates a dateframe with datetime ranging from 2017/01/01 to 2018/12/31
import numpy as np

date_range = pd.date_range("2017-01-01 00:00:00", "2017-12-31 23:00:00", freq='1H').append(pd.date_range("2018-01-01 00:00:00","2018-12-31 23:00:00", freq='1H'))

df_total = pd.DataFrame(columns = ['date', 'speed'])
df_total['date'] = date_range
df_total['speed'] = np.nan
df_total.iloc[:5]

# merge train data into a complete time range file to detect the missing value
df2 = pd.merge(df_total, df, on='date', how = 'left')
df2.iloc[:5]

df2 = df2[['date','speed_y']]
df2.columns = ['date', 'speed']
df2.iloc[:5]

df2['date_hour'] = df2.date.map(lambda x: x.strftime('%Y-%m-%d-%H'))
temp = df2[['date_hour','speed']]
temp.iloc[:5]

# detect the linear trending of the speed for each hour
from sklearn import linear_model

def nan_helper(y):
  return np.isnan(y), lambda z: z.nonzero()[0]

y = temp['speed'].values
nans, x = nan_helper(y)
regr = linear_model.LinearRegression()
regr.fit(x(~nans).reshape(-1,1), y[~nans].reshape(-1,1))
temp['date_trend'] = regr.predict(temp.index.values.reshape(-1,1)).ravel()
df2 = pd.merge(df2, temp[['date_trend','date_hour']], on='date_hour', how='left')
df2.iloc[:5]

df2.drop(['date_hour'],axis=1,inplace=True)
df2.columns = ['date','speed','date_trend']
df2.iloc[:5]

df2[['speed','date_trend']].plot()
plt.show()

# extract the time features
df2['speed'] = df2['speed'] - df2['date_trend']
df2['minute'] = df2['date'].dt.minute
df2['hour'] = df2['date'].dt.hour
df2['day'] = df2['date'].dt.day
df2['week_day'] = df2['date'].map(lambda x: x.weekday()+1)
df2['month'] = df2['date'].dt.month

df2.iloc[:5]

# add the vacation features
df2['speed_std'] = np.std(df2['speed'])
df2['speed'] = df2['speed'] / df2['speed_std']
df2.loc[df2['date'].isin(
    ['2017-01-02', '2017-01-28', '2017-01-30', '2017-01-31', '2017-04-04', '2017-04-14', '2017-04-15', '2017-04-17', '2017-05-01',
     '2017-05-03', '2017-05-30', '2017-07-01', '2017-10-02', '2017-10-05', '2017-10-28', '2017-12-25', '2017-12-26',
     '2018-01-02', '2018-01-28', '2018-01-30', '2018-01-31', '2018-04-04', '2018-04-14', '2018-04-15', '2018-04-17', '2018-05-01',
     '2018-05-03', '2018-05-30', '2018-07-01', '2018-10-02', '2018-10-05', '2018-10-28', '2018-12-25', '2018-12-26']), 'vacation'] = 1

df2.loc[~df2['date'].isin(
    ['2017-01-02', '2017-01-28', '2017-01-30', '2017-01-31', '2017-04-04', '2017-04-14', '2017-04-15', '2017-04-17', '2017-05-01',
     '2017-05-03', '2017-05-30', '2017-07-01', '2017-10-02', '2017-10-05', '2017-10-28', '2017-12-25', '2017-12-26',
     '2018-01-02', '2018-01-28', '2018-01-30', '2018-01-31', '2018-04-04', '2018-04-14', '2018-04-15', '2018-04-17', '2018-05-01',
     '2018-05-03', '2018-05-30', '2018-07-01', '2018-10-02', '2018-10-05', '2018-10-28', '2018-12-25', '2018-12-26']), 'vacation'] = 0

df2.iloc[:5]

# detect the week_day feature
df2.loc[df2['week_day'].isin([1, 2, 3, 4, 5]), 'day_of_week'] = 1
df2.loc[df2['week_day'] == 6, 'day_of_week'] = 2
df2.loc[df2['week_day'] == 7, 'day_of_week'] = 3

df2.iloc[:5]

# detect the month trend
df2.loc[df2['month'].isin([10,11,12,1]), 'month_of_year'] = 1
df2.loc[df2['month'] == 9, 'month_of_year'] = 2
df2.loc[df2['month'] == 8, 'month_of_year'] = 3
df2.loc[df2['month'].isin([3,4,5,7]), 'month_of_year'] = 4
df2.loc[df2['month'] == 2, 'month_of_year'] = 5

df2.iloc[:5]

# detect the hour trend
df2.loc[df2['hour'].isin([22,23,0,1,2,3,4,5]), 'hour_of_day'] = 1
df2.loc[df2['hour'].isin([6,7,8,9,10]), 'hour_of_day'] = 2
df2.loc[df2['hour'].isin([11,12,13,14,15,16,17]), 'hour_of_day'] = 3
df2.loc[df2['hour'].isin([18,19,20,21]), 'hour_of_day'] = 4

df2.loc[df2['hour'].isin([7,8,9]), 'rush_hour'] = 1
df2.loc[df2['hour'].isin([17,18,19]), 'rush_hour'] = 1
df2.loc[~df2['hour'].isin([7,8,9,17,18,19]), 'rush_hour'] = 0

df2.iloc[:5]

# determine the train features
train_data = df2

feature = train_data.columns.values.tolist()
train_feature = [x for x in feature if x not in ['date','speed','speed_std','date_trend']]
# train_feature = [x for x in feature if x not in ['date','speed','speed_std','date_trend', 'minute', 'hour', 'day', 'week_day', 'month']]

train_df = train_data.loc[~train_data['speed'].isnull()]
test_df = train_data.loc[train_data['speed'].isnull()].copy()
print(train_feature)

test_df.iloc[:5]

from sklearn.model_selection import train_test_split

X = train_df[train_feature].values
y = train_df['speed'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)
eval_set = [(X_test, y_test)]

print(train_feature)

# train the xgboost model
from xgboost.sklearn import XGBRegressor

params = {
    'learning_rate': 0.1,
    'n_estimators': 1000,
    'subsample': 0.8,
    'colsample_bytree': 0.6,
    'max_depth': 12,
    'min_child_weight': 1,
    'reg_alpha': 1,
    'gamma': 0
}

regressor = XGBRegressor(learning_rate=params['learning_rate'], n_estimators=params['n_estimators'],
                             booster='gbtree', objective='reg:linear', n_jobs=-1, subsample=params['subsample'],
                             colsample_bytree=params['colsample_bytree'], random_state=0,
                             max_depth=params['max_depth'], gamma=params['gamma'],
                             min_child_weight=params['min_child_weight'], reg_alpha=params['reg_alpha'])

regressor.fit(X_train, y_train, verbose=True, early_stopping_rounds=10, eval_set=eval_set)

# use the trained model to predict in the test data
test_df['prediction'] = regressor.predict(test_df[train_feature].values)
test_df.iloc[:5]

df2 = pd.merge(df2, test_df[['date','prediction']], on=['date'],how='left')
df2.iloc[-5:]

# calculate the final speed
df2['imputationa1'] = df2['speed'].isnull()
df2['speed'] = df2['speed'].fillna(value=df2['prediction'])
df2['speed'] = (df2['speed'] * np.array(df2['speed_std']) + np.array(df2['date_trend']))
df2[-5:]

# visualize the prediction results
temp = df2.loc[df2['imputationa1'] == False]
tmp = df2.loc[df2['imputationa1'] == True]
plt.scatter(temp.index, temp['speed'], c='b')
plt.scatter(tmp.index, tmp['speed'], c='r')
plt.show()

df2.to_csv('prediction_1205_1.csv')

"""## XGBOOST"""

df2.iloc[-5:]
store_df = df2

def create_lagging(df, df_original, i):
  df1 = df_original.copy()
  df1['date'] = df1['date'] + pd.DateOffset(hours=i * 1)
  df1 = df1.rename(columns={'speed': 'lagging' + str(i)})
  df2 = pd.merge(df, df1[['date', 'lagging' + str(i)]],
                  on='date',
                  how='left')
  return df2

lagging = 5
df = create_lagging(df2, df2, 1)
for i in range(2, lagging + 1):
  df = create_lagging(df, df2, i)

df.iloc[:5]

df2.iloc[20:30]

df2.loc[df['date'].dt.month.isin(range(1,13))].groupby(['hour', 'week_day'])[
    'speed'].mean().unstack().plot()
plt.show()

df2.loc[df['date'].dt.month.isin(range(1,13))].groupby(['month', 'week_day'])[
    'speed'].mean().unstack().plot()
plt.show()

df2.loc[df2['week_day'].isin([1, 2, 3, 4, 5]), 'day_of_week'] = 1
df2.loc[df2['week_day'] == 6, 'day_of_week'] = 2
df2.loc[df2['week_day'] == 7, 'day_of_week'] = 3

df2.iloc[:5]

df2.loc[df2['month'].isin([10,11,12,1]), 'month_of_year'] = 1
df2.loc[df2['month'] == 9, 'month_of_year'] = 2
df2.loc[df2['month'] == 8, 'month_of_year'] = 3
df2.loc[df2['month'].isin([3,4,5,7]), 'month_of_year'] = 4
df2.loc[df2['month'] == 2, 'month_of_year'] = 5

df2.iloc[:5]

df2.loc[df2['hour'].isin([22,23,0,1,2,3,4,5]), 'hour_of_day'] = 1
df2.loc[df2['hour'].isin([6,7,8,9,10]), 'hour_of_day'] = 2
df2.loc[df2['hour'].isin([11,12,13,14,15,16,17]), 'hour_of_day'] = 3
df2.loc[df2['hour'].isin([18,19,20,21]), 'hour_of_day'] = 4

df2.iloc[:5]

df2['week_hour'] = df2["day_of_week"].astype('str') + "," + df2["hour_of_day"].astype('str')
df2.boxplot(by=['week_hour'], column='speed')
plt.show()

df2.loc[df2['date'].isin(
    ['2018-01-02', '2018-01-28', '2018-01-30', '2018-01-31', '2018-04-04', '2018-04-14', '2018-04-15', '2018-04-17', '2018-05-01',
     '2018-05-03', '2018-05-30', '2018-07-01', '2018-10-02', '2018-10-05', '2018-10-28', '2018-12-25', '2018-12-26']), 'vacation'] = 1

df2.loc[~df2['date'].isin(
    ['2018-01-02', '2018-01-28', '2018-01-30', '2018-01-31', '2018-04-04', '2018-04-14', '2018-04-15', '2018-04-17', '2018-05-01',
     '2018-05-03', '2018-05-30', '2018-07-01', '2018-10-02', '2018-10-05', '2018-10-28', '2018-12-25', '2018-12-26']), 'vacation'] = 0

df2.iloc[:5]

df2 = pd.merge(df2,df[['date','lagging1','lagging2','lagging3','lagging4','lagging5']],on='date',how='left')
df2.iloc[:5]

from sklearn.externals import joblib
from sklearn.model_selection import ParameterGrid

train_df = df2.loc[df2['date'] < pd.to_datetime('2018-01-01')]
train_df.iloc[:5]

train_df = train_df.dropna()

feature = train_df.columns.values.tolist()
# train_feature = [x for x in feature if x not in ['date', 'speed', 'date_trend', 'minute', 'hour', 
#                                                  'day', 'week_day', 'month', 'speed_std',
#                                                  'prediction', 'imputationa1','week_hour']]
train_feature = [x for x in feature if x not in ['date', 'speed', 'date_trend', 'minute', 'week_day', 'month', 'vacation',
                                                 'day', 'speed_std',
                                                 'prediction', 'imputationa1','week_hour']]

X = train_df[train_feature].values
y = train_df['speed'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)

print(train_feature)

test_df = df2.loc[df2['date'] >= pd.to_datetime('2018-01-01')]
test_df.iloc[:5]

def cross_valid(regressor, bucket, lagging):
  valid_loss = []
  last = [[] for i in range(len(bucket[bucket.keys()[0]]))]
  for time_series in sorted(bucket.keys(), key=float):
    if time_series >= 120:
      if int(time_series) in range(120, 120 + lagging * 2, 2):
        last = np.concatenate((last, np.array(bucket[time_series], dtype=float)[:, -1].reshape(-1, 1)), axis=1)
      else:
        batch = np.array(bucket[time_series], dtype=float)
        y = batch[:, -1]
        batch = np.delete(batch, -1, axis=1)
        batch = np.concatenate((batch, last), axis=1)
        y_pre = regressor.predict(batch)
        last = np.delete(last, 0, axis=1)
        last = np.concatenate((last, y_pre.reshape(-1, 1)), axis=1)
        loss = np.mean(abs(np.expm1(y) - np.expm1(y_pre)) / np.expm1(y))
        valid_loss.append(loss)
  # print 'day: %d loss: %f' % (int(day), day_loss)
  return np.mean(valid_loss)


def mape_ln(y, d):
  c = d.get_label()
  result = np.sum(np.abs((np.expm1(y) - np.expm1(c)) / np.expm1(c))) / len(c)
  return "mape", result

eval_set = [(X_test, y_test)]

params = {
    'learning_rate': 0.2,
    'n_estimators': 1000,
    'subsample': 0.6,
    'colsample_bytree': 0.8,
    'max_depth': 15,
    'min_child_weight': 1,
    'reg_alpha': 2,
    'gamma': 0
}

regressor2 = XGBRegressor(learning_rate=params['learning_rate'], n_estimators=params['n_estimators'],
                              booster='gbtree', objective='reg:linear', n_jobs=-1, subsample=params['subsample'],
                              colsample_bytree=params['colsample_bytree'], random_state=0,
                              max_depth=params['max_depth'], gamma=params['gamma'],
                              min_child_weight=params['min_child_weight'], reg_alpha=params['reg_alpha'])

regressor2.fit(X_train, y_train, verbose=True, early_stopping_rounds=10, eval_metric=mape_ln,
                  eval_set=eval_set)

test_df['prediction_xgb'] = regressor2.predict(test_df[train_feature].values)
# test_df['prediction_xgb'] = (test_df['prediction_xgb'] * np.array(test_df['speed_std']) + np.array(test_df['date_trend']))
test_df.iloc[:10]

plot_df = pd.DataFrame(test_df,columns=['speed','prediction_xgb'])
plot_df.plot()
plt.show()

test_df.to_csv('prediction_1204_1.csv')